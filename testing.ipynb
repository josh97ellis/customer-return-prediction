{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "1. Create the most accurate classifier (evaluation metric: accuracy rate) for the data, as measured by the\n",
    "test data.\n",
    "2. Write a 8-12 page slides summarizing your approach to:  \n",
    "    (a) cleaning and preparing the data for modeling - Assumption: Missing dates implying no delivery  \n",
    "    (b) formulating the model design matrix - Definition of features  \n",
    "    (c) building the model and tuning parameters - Different models tested and describe the tuning process  \n",
    "    (d) validating the model by training & validation sets, or other approaches - 5-fold Cross-Validation   \n",
    "    (e) comparing results from all attempts  \n",
    "    (f) findings from the data and challenges from this contest.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, LabelEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from src.datasets import get_training\n",
    "from src.prep import DataPrep\n",
    "from src.utils import make_predictions, evaluate_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get and Prepare Training Data**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read training X and y frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training()\n",
    "xy = X.join(y)\n",
    "xy = xy[pd.to_datetime(xy['deliveryDate'], errors='coerce').dt.year != 1990]\n",
    "\n",
    "X = xy.drop(columns='return')\n",
    "y = xy['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training()\n",
    "\n",
    "# Training Set\n",
    "train_set = X[pd.to_datetime(X['orderDate']) < pd.to_datetime('2022-02-01')].join(y)\n",
    "X_train = train_set.drop(columns='return')\n",
    "y_train = train_set['return']\n",
    "\n",
    "# Validation Set\n",
    "validation_set = X[pd.to_datetime(X['orderDate']) >= pd.to_datetime('2022-02-01')].join(y)\n",
    "X_val = validation_set.drop(columns='return')\n",
    "y_val = validation_set['return']\n",
    "\n",
    "# Prepped and Cleaned Sets\n",
    "X_prep = DataPrep().run(X)\n",
    "X_train_prep = DataPrep().run(X_train)\n",
    "X_val_prep = DataPrep().run(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep.drop(columns=['size'], inplace=True)\n",
    "X_val_prep.drop(columns=['size'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>price</th>\n",
       "      <th>salutation</th>\n",
       "      <th>state</th>\n",
       "      <th>customer_age_at_order</th>\n",
       "      <th>account_age_months</th>\n",
       "      <th>order_month</th>\n",
       "      <th>is_delivered</th>\n",
       "      <th>customer_return_rate</th>\n",
       "      <th>customer_order_count</th>\n",
       "      <th>item_return_rate</th>\n",
       "      <th>manufacturer_return_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>magenta</td>\n",
       "      <td>79.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.5438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>89.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>0.5183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grey</td>\n",
       "      <td>39.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Lower Saxony</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brown</td>\n",
       "      <td>139.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>North Rhine-Westphalia</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown</td>\n",
       "      <td>54.95</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Lower Saxony</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183903</th>\n",
       "      <td>black</td>\n",
       "      <td>59.95</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183904</th>\n",
       "      <td>black</td>\n",
       "      <td>69.95</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183905</th>\n",
       "      <td>black</td>\n",
       "      <td>59.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.4507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183906</th>\n",
       "      <td>black</td>\n",
       "      <td>59.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Rhineland-Palatinate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.4507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183907</th>\n",
       "      <td>black</td>\n",
       "      <td>59.90</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.4507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183908 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          color   price salutation                   state  \\\n",
       "0       magenta   79.90        Mrs                   Hesse   \n",
       "1          blue   89.90        Mrs                  Berlin   \n",
       "2          grey   39.90        Mrs            Lower Saxony   \n",
       "3         brown  139.90        Mrs  North Rhine-Westphalia   \n",
       "4         brown   54.95         Mr            Lower Saxony   \n",
       "...         ...     ...        ...                     ...   \n",
       "183903    black   59.95         Mr                 Hamburg   \n",
       "183904    black   69.95         Mr                 Hamburg   \n",
       "183905    black   59.90        Mrs                 Bavaria   \n",
       "183906    black   59.90        Mrs    Rhineland-Palatinate   \n",
       "183907    black   59.90        Mrs                   Hesse   \n",
       "\n",
       "        customer_age_at_order  account_age_months  order_month  is_delivered  \\\n",
       "0                         NaN                 0.0            9             1   \n",
       "1                        61.0                18.0            9             1   \n",
       "2                        42.0                 0.0            9             1   \n",
       "3                        40.0                18.0            9             1   \n",
       "4                        53.0                 0.0            9             1   \n",
       "...                       ...                 ...          ...           ...   \n",
       "183903                   26.0                 0.0            1             0   \n",
       "183904                   26.0                 0.0            1             0   \n",
       "183905                   49.0                 1.0            1             1   \n",
       "183906                    NaN                 0.0            1             1   \n",
       "183907                   41.0                 0.0            1             1   \n",
       "\n",
       "        customer_return_rate  customer_order_count  item_return_rate  \\\n",
       "0                     0.0000                     4            0.4324   \n",
       "1                     0.4545                    22            0.7931   \n",
       "2                     0.4545                    11            0.5000   \n",
       "3                     0.6667                    15            0.4000   \n",
       "4                     0.0000                     2            0.1538   \n",
       "...                      ...                   ...               ...   \n",
       "183903                0.0000                     6            0.0000   \n",
       "183904                0.0000                     6            0.0000   \n",
       "183905                0.3333                     3            0.5714   \n",
       "183906                0.4000                     5            0.5714   \n",
       "183907                0.5333                    15            0.5714   \n",
       "\n",
       "        manufacturer_return_rate  \n",
       "0                         0.5438  \n",
       "1                         0.5183  \n",
       "2                         0.5516  \n",
       "3                         0.5438  \n",
       "4                         0.2957  \n",
       "...                          ...  \n",
       "183903                    0.3973  \n",
       "183904                    0.3973  \n",
       "183905                    0.4507  \n",
       "183906                    0.4507  \n",
       "183907                    0.4507  \n",
       "\n",
       "[183908 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Steps*\n",
    "1. Encode the categorical variables\n",
    "    - OneHotEncoder for non-tree models\n",
    "    - OrdinalEncoder for tree-based models\n",
    "2. Impute missing values on numeric fields\n",
    "    - SimpleImputer [mean, median, most_frequent]\n",
    "3. Scale numerical values\n",
    "4. [optional] normalize features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Notes*\n",
    "- For tree-based models, do not one-hot encode, instead use ordinal encoding. Tree-based models can basically learn the same information from an ordinal encoded feature as from a one-hot encoded feature, even if the features themselves are unordered.\n",
    "- Cross-Validation on the entire pipeline\n",
    "    - Data is split and then applies the pipeline steps (good) instead of preprocessing the data and then do cross-validation on just the model (bad - Data Leakage)\n",
    "    - Preprocessing before splitting the data does not properly simulate reality\n",
    "    - Splitting and then preprocessing does simulate reality, which is the entire purpose of cross-validation\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Preprocessors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of numerical and categorical columns in X data\n",
    "numeric_cols = X_train_prep.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_train_prep.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a preprocessor for tree-based models\n",
    "treebased_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "        ]), categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('normalize', Normalizer(norm='max'))\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('normalize', Normalizer(norm='max'))\n",
    "        ]), numeric_cols)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Development and Testing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models to Test*\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- SVC\n",
    "- Decision Tree\n",
    "- Bagging Decision Tree\n",
    "- Boosted Decision Tree\n",
    "- Random Forest Classifier\n",
    "- Voting Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 1: Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7871109467777367\n",
      "Validation Score: 0.7732338153734515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initilize Classifier with the best parameters\n",
    "clf = DecisionTreeClassifier(\n",
    "    min_samples_split=4,\n",
    "    max_depth=11,\n",
    "    splitter='best',\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "# Create a ML Pipeline Instance with the Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "evaluate_model(pipeline, X_train_prep, X_val_prep, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 2: XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7850555712638928\n",
      "Validation Score: 0.783133779090862\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(n_estimators=220, objective='binary:logistic', tree_method='hist', learning_rate=0.10, max_depth=4)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "evaluate_model(pipeline, X_train_prep, X_val_prep, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 3: Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7875405093851273\n",
      "Validation Score: 0.782408127300057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize Base Classifier\n",
    "clf = GradientBoostingClassifier(\n",
    "    min_samples_split=10,\n",
    "    max_depth=8,\n",
    "    n_estimators=25,\n",
    "    max_features=9\n",
    ")\n",
    "\n",
    "# Initialize ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "evaluate_model(pipeline, X_train_prep, X_val_prep, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 4: SGDClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7439698109924527\n",
      "Validation Score: 0.7448556471259006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Initialize Tuned Classifier\n",
    "clf = SGDClassifier(\n",
    "    penalty='l1',\n",
    "    max_iter=1000,\n",
    "    loss='modified_huber',\n",
    "    alpha=0.0001\n",
    ")\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "evaluate_model(pipeline, X_train_prep, X_val_prep, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 5: Multi-Layer Perceptron Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josh Ellis\\Anaconda3\\envs\\uno-env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Josh Ellis\\Anaconda3\\envs\\uno-env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7881386345346586\n",
      "Validation Score: 0.7710568600010367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Fit base pipeline to training data\n",
    "pipeline.fit(X_train_prep, y_train)\n",
    "\n",
    "evaluate_model(pipeline, X_train_prep, X_val_prep, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 6: Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.781581007895252\n",
      "Validation Score: 0.7723267506349453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    max_depth=10,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "evaluate_model(pipeline, X_train_prep, X_val_prep, y_train, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model and Predict Test Set        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_estimators=220, objective='binary:logistic', tree_method='hist', learning_rate=0.1, max_depth=4)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Fit base pipeline to training data\n",
    "pipeline.fit(X_prep, y)\n",
    "\n",
    "make_predictions(pipeline, 'submission9_xgboost.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
