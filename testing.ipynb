{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "1. Create the most accurate classifier (evaluation metric: accuracy rate) for the data, as measured by the\n",
    "test data.\n",
    "2. Write a 8-12 page slides summarizing your approach to:  \n",
    "    (a) cleaning and preparing the data for modeling - Assumption: Missing dates implying no delivery  \n",
    "    (b) formulating the model design matrix - Definition of features  \n",
    "    (c) building the model and tuning parameters - Different models tested and describe the tuning process  \n",
    "    (d) validating the model by training & validation sets, or other approaches - 5-fold Cross-Validation   \n",
    "    (e) comparing results from all attempts  \n",
    "    (f) findings from the data and challenges from this contest.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, LabelEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from src.datasets import get_training\n",
    "from src.prep import DataPrep\n",
    "from src.utils import model_evaluation_cv, make_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get and Prepare Training Data**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read training X and y frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training()\n",
    "X_prepped = DataPrep().run(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Filter training data, removing customers with age > 100*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevent Indexes to keep\n",
    "keep_idx = X_prepped[(X_prepped['customer_age_at_order'] < 100) | (X_prepped['customer_age_at_order'].isna())].index\n",
    "\n",
    "# Filter our data in X and y\n",
    "X_prepped = X_prepped.loc[keep_idx]\n",
    "y = X_prepped.join(y)['return']\n",
    "\n",
    "# Reset index from 0-n\n",
    "X_prepped.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Steps*\n",
    "1. Encode the categorical variables\n",
    "    - OneHotEncoder for non-tree models\n",
    "    - OrdinalEncoder for tree-based models\n",
    "2. Impute missing values on numeric fields\n",
    "    - SimpleImputer [mean, median, most_frequent]\n",
    "3. Scale numerical values\n",
    "4. [optional] normalize features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Notes*\n",
    "- For tree-based models, do not one-hot encode, instead use ordinal encoding. Tree-based models can basically learn the same information from an ordinal encoded feature as from a one-hot encoded feature, even if the features themselves are unordered.\n",
    "- Cross-Validation on the entire pipeline\n",
    "    - Data is split and then applies the pipeline steps (good) instead of preprocessing the data and then do cross-validation on just the model (bad - Data Leakage)\n",
    "    - Preprocessing before splitting the data does not properly simulate reality\n",
    "    - Splitting and then preprocessing does simulate reality, which is the entire purpose of cross-validation\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Preprocessors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of numerical and categorical columns in X data\n",
    "numeric_cols = X_prepped.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_prepped.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a preprocessor for tree-based models\n",
    "treebased_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Development and Testing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models to Test*\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- SVC\n",
    "- Decision Tree\n",
    "- Bagging Decision Tree\n",
    "- Boosted Decision Tree\n",
    "- Random Forest Classifier\n",
    "- Voting Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 1: Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.48026037 1.54868555 1.3789115  1.31208324 1.30005002]\n",
      "score_time [0.11382413 0.09935117 0.0985651  0.09071136 0.10803843]\n",
      "test_score [0.65700209 0.66681046 0.65784216 0.65638907 0.67066276]\n",
      "train_score [0.97544487 0.97531999 0.97638144 0.97743153 0.97623399]\n",
      "-----\n",
      "Average cross-validation test score: 0.6617413071599373\n",
      "Average cross-validation train score: 0.9761623655637937\n"
     ]
    }
   ],
   "source": [
    "# Initialize Base Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize a Base ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate performance on base model\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperparameter Tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Accuracy: 0.7669682858975142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__splitter': 'random',\n",
       " 'model__min_samples_split': 4,\n",
       " 'model__max_depth': 8,\n",
       " 'model__criterion': 'gini'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base ML Pipeline using Decision Tree\n",
    "clf = DecisionTreeClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create the parameter grid for hyper-parameter tuning\n",
    "param_grid = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [2, 4, 6, 8, 10],\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'model__splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# Test 10 random hyperparameter combinations with 5-fold CV\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, param_grid, n_iter=20, cv=5, scoring='accuracy',\n",
    "    verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "search.fit(X_prepped, y)\n",
    "\n",
    "# Evaluate results of the search\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "print(f'Best Accuracy: {search.best_score_}')\n",
    "search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Evaluate the Tuned Decision Tree Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [0.75663996 0.73046374 0.72963119 0.70372248 0.6866312 ]\n",
      "score_time [0.08802986 0.09773564 0.10615492 0.09615111 0.1078043 ]\n",
      "test_score [0.77183757 0.76968022 0.77296119 0.7578822  0.76142748]\n",
      "train_score [0.77166213 0.77017894 0.77166213 0.7697351  0.77586575]\n",
      "-----\n",
      "Average cross-validation test score: 0.7667577313084784\n",
      "Average cross-validation train score: 0.7718208086005227\n"
     ]
    }
   ],
   "source": [
    "# Initilize Classifier with the best parameters\n",
    "clf = DecisionTreeClassifier(\n",
    "    min_samples_split=4,\n",
    "    max_depth=8,\n",
    "    splitter='random',\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "# Create a ML Pipeline Instance with the Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 2: SGDClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Evaluate Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.06982088 1.0507679  1.02597451 1.03102064 1.0332787 ]\n",
      "score_time [0.10078168 0.10587502 0.10735512 0.09990263 0.10965347]\n",
      "test_score [0.76632458 0.76444011 0.76875397 0.75635728 0.76100629]\n",
      "train_score [0.76243508 0.76275294 0.76167447 0.76612459 0.76496231]\n",
      "-----\n",
      "Average cross-validation test score: 0.7633764463095509\n",
      "Average cross-validation train score: 0.7635898794240836\n"
     ]
    }
   ],
   "source": [
    "# Initialize Base Classifier\n",
    "clf = SGDClassifier()\n",
    "\n",
    "# Initialize ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Evaluate Hyperparameter-tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7584540882000183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__penalty': 'l1',\n",
       " 'model__max_iter': 1000,\n",
       " 'model__loss': 'modified_huber',\n",
       " 'model__alpha': 0.0001}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base ML Pipeline using SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create the parameter grid for hyper-parameter tuning\n",
    "param_grid = {\n",
    "    'model__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'model__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'model__max_iter': [1000, 5000, 10000]}\n",
    "\n",
    "# Test 10 random hyperparameter combinations with 5-fold CV\n",
    "search = RandomizedSearchCV(pipeline, param_grid, n_iter=10, cv=5, scoring='accuracy', return_train_score=False, random_state=42, n_jobs=-1)\n",
    "search.fit(X_prepped, y)\n",
    "\n",
    "# Evaluate results of the search\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "print(f'Best Accuracy: {search.best_score_}')\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.30916095 1.39068055 1.20214367 1.1642735  1.30064988]\n",
      "score_time [0.09161973 0.09718871 0.09606147 0.09177518 0.09867525]\n",
      "test_score [0.77027518 0.76419036 0.74477795 0.75692489 0.75823627]\n",
      "train_score [0.7645977  0.7668852  0.76970058 0.77236838 0.77172827]\n",
      "-----\n",
      "Average cross-validation test score: 0.7588809292356239\n",
      "Average cross-validation train score: 0.769056027554112\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tuned Classifier\n",
    "clf = SGDClassifier(\n",
    "    penalty='l1',\n",
    "    max_iter=1000,\n",
    "    loss='modified_huber',\n",
    "    alpha=0.0001\n",
    ")\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [3.36990643 2.58722329 2.31067395 2.3189652  2.31309247]\n",
      "score_time [0.15515924 0.11544895 0.11325622 0.11164474 0.11375284]\n",
      "test_score [0.759  0.7584 0.7496 0.7706 0.7528]\n",
      "train_score [0.98315 0.9837  0.98365 0.9839  0.9836 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.75808\n",
      "Average cross-validation train score: 0.9836\n"
     ]
    }
   ],
   "source": [
    "model = model=RandomForestClassifier()\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', model)])\n",
    "\n",
    "model_evaluation(random_forest_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 500,\n",
       " 'model__min_samples_split': 12,\n",
       " 'model__min_samples_leaf': 2,\n",
       " 'model__max_features': 'log2',\n",
       " 'model__max_depth': 10,\n",
       " 'model__bootstrap': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model=RandomForestClassifier()\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', model)])\n",
    "\n",
    "random_forest_param_grid = {\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__max_depth': [5, 7, 10, 12, 15],\n",
    "    'model__max_features': [None, 'sqrt', 'log2'],\n",
    "    'model__min_samples_leaf': [1, 2, 3],\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10, 12],\n",
    "    'model__n_estimators': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=random_forest_pipeline,\n",
    "    param_distributions=random_forest_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1).fit(X.head(25000), y.head(25000))\n",
    "\n",
    "print(rf_random.best_score_)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [6.54380774 6.54193783 6.28002405 6.67028141 6.45264959]\n",
      "score_time [0.29910493 0.2912569  0.28822875 0.30168414 0.29417658]\n",
      "test_score [0.7644 0.7798 0.768  0.7846 0.7632]\n",
      "train_score [0.7903  0.7912  0.79395 0.7886  0.7916 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.772\n",
      "Average cross-validation train score: 0.7911300000000001\n"
     ]
    }
   ],
   "source": [
    "tuned_model = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=6,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "tuned_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', tuned_model)])\n",
    "\n",
    "# Model Evaluation\n",
    "model_evaluation(tuned_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = X_prepped.sample(25000).join(y)\n",
    "X_prepped_sample = sampled_df.drop(columns=['return'])\n",
    "y_sample = sampled_df['return']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Evaluate Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([23.12288785, 25.16459703, 22.36177158, 22.81326747, 21.2776823 ]),\n",
       " 'score_time': array([3.48576641, 2.9429872 , 2.89863014, 2.67603254, 2.62749577]),\n",
       " 'test_score': array([0.7772, 0.7844, 0.7684, 0.7874, 0.7604])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Base SVC Model\n",
    "clf = SVC()\n",
    "\n",
    "# Initialize base ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "cross_validate(estimator=pipeline, X=X_prepped.head(25000), y=y.head(25000), cv=5, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Evaluate hyperparameter tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__kernel': 'rbf', 'model__gamma': 'scale', 'model__C': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a base pipelipe\n",
    "clf = SVC()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create Parameter Grid for RandomizedSearch\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'model__gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Runing Hyperparameter Tuning Search Procedure\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1).fit(X_prepped_sample, y_sample)\n",
    "\n",
    "# Evaluate best model parameters\n",
    "print(search.best_score_)\n",
    "search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3: Evaluate performace of tuned model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tuned SVC Model\n",
    "clf = SVC(\n",
    "    kernel='rbf',\n",
    "    gammer='scale',\n",
    "    C=1\n",
    ")\n",
    "\n",
    "# Initialize Tuned ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Tuned Model Performance\n",
    "cross_validate(estimator=pipeline, X=X_prepped_sample, y=y_sample, cv=5, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = X_prepped.sample(25000).join(y)\n",
    "X_prepped_sample = sampled_df.drop(columns=['return'])\n",
    "y_sample = sampled_df['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [10.23965383 10.5209434  10.18956566 10.10906339 10.14805746]\n",
      "score_time [0.32194686 0.36301517 0.29652238 0.29341698 0.31455374]\n",
      "test_score [0.772  0.7706 0.7562 0.7728 0.773 ]\n",
      "train_score [0.76915 0.7692  0.77275 0.7692  0.7693 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.76892\n",
      "Average cross-validation train score: 0.7699199999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "tree = DecisionTreeClassifier(\n",
    "    min_samples_split=8,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "# Initialize a bagging classifier with 10 decision trees\n",
    "bagging = BaggingClassifier(tree, n_estimators=500)\n",
    "\n",
    "bagging_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', bagging)])\n",
    "\n",
    "model_evaluation_cv(bagging_pipeline, X_prepped_sample, y_sample, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model and Predict Test Set        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['color', 'salutation', 'state', 'order_month',\n",
       "       'customer_return_behavior', 'item_return_behavior',\n",
       "       'manufacturer_return_behavior'],\n",
       "      dtype='object')),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index(['size', 'price', 'customer_age_at_order', 'account_age_months',\n",
       "       'is_delivered'],\n",
       "      dtype='object'))])),\n",
       "                ('model', SVC(C=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = X_prepped.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_prepped.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Initialize Tuned Classifier\n",
    "clf = SVC(\n",
    "    kernel='rbf',\n",
    "    gamma= 'scale',\n",
    "    C= 1)\n",
    "\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "pipeline.fit(X_prepped.head(25000), y.head(25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(pipeline, 'submission3_svc_sampled.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7786516853932585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_prepped, y, test_size=.10)\n",
    "\n",
    "clf = XGBClassifier(n_estimators=100, objective='binary:logistic', tree_method='hist', eta=0.1, max_depth=4)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  Index([&#x27;color&#x27;, &#x27;manufacturerID&#x27;, &#x27;salutation&#x27;, &#x27;state&#x27;, &#x27;order_month&#x27;,\n",
       "       &#x27;customer_return_behavior&#x27;, &#x27;item_return_behavior&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[...\n",
       "                               eval_metric=None, feature_types=None, gamma=None,\n",
       "                               gpu_id=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  Index([&#x27;color&#x27;, &#x27;manufacturerID&#x27;, &#x27;salutation&#x27;, &#x27;state&#x27;, &#x27;order_month&#x27;,\n",
       "       &#x27;customer_return_behavior&#x27;, &#x27;item_return_behavior&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[...\n",
       "                               eval_metric=None, feature_types=None, gamma=None,\n",
       "                               gpu_id=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 Index([&#x27;color&#x27;, &#x27;manufacturerID&#x27;, &#x27;salutation&#x27;, &#x27;state&#x27;, &#x27;order_month&#x27;,\n",
       "       &#x27;customer_return_behavior&#x27;, &#x27;item_return_behavior&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 Index([&#x27;size&#x27;, &#x27;price&#x27;, &#x27;customer_age_at_order&#x27;, &#x27;account_age_months&#x27;,\n",
       "       &#x27;is_delivered&#x27;, &#x27;total_orders&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;color&#x27;, &#x27;manufacturerID&#x27;, &#x27;salutation&#x27;, &#x27;state&#x27;, &#x27;order_month&#x27;,\n",
       "       &#x27;customer_return_behavior&#x27;, &#x27;item_return_behavior&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;size&#x27;, &#x27;price&#x27;, &#x27;customer_age_at_order&#x27;, &#x27;account_age_months&#x27;,\n",
       "       &#x27;is_delivered&#x27;, &#x27;total_orders&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['color', 'manufacturerID', 'salutation', 'state', 'order_month',\n",
       "       'customer_return_behavior', 'item_return_behavior'],\n",
       "      dtype='object')),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[...\n",
       "                               eval_metric=None, feature_types=None, gamma=None,\n",
       "                               gpu_id=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, ...))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(n_estimators=100, objective='binary:logistic', tree_method='hist', eta=0.1, max_depth=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "pipeline.fit(X_prepped, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(pipeline, 'submission5_xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x2b32c8474f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_booster()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
