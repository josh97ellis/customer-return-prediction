{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "1. Create the most accurate classifier (evaluation metric: accuracy rate) for the data, as measured by the\n",
    "test data.\n",
    "2. Write a 8-12 page slides summarizing your approach to:  \n",
    "    (a) cleaning and preparing the data for modeling - Assumption: Missing dates implying no delivery  \n",
    "    (b) formulating the model design matrix - Definition of features  \n",
    "    (c) building the model and tuning parameters - Different models tested and describe the tuning process  \n",
    "    (d) validating the model by training & validation sets, or other approaches - 5-fold Cross-Validation   \n",
    "    (e) comparing results from all attempts  \n",
    "    (f) findings from the data and challenges from this contest.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, LabelEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from src.datasets import get_training\n",
    "from src.prep import DataPrep\n",
    "from src.utils import model_evaluation_cv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get and Prepare Training Data**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read training X and y frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training()\n",
    "X_prepped = DataPrep().run(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Filter training data, removing customers with age > 100*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevent Indexes to keep\n",
    "keep_idx = X_prepped[(X_prepped['customer_age_at_order'] < 100) | (X_prepped['customer_age_at_order'].isna())].index\n",
    "\n",
    "# Filter our data in X and y\n",
    "X_prepped = X_prepped.loc[keep_idx]\n",
    "y = X_prepped.join(y)['return']\n",
    "\n",
    "# Reset index from 0-n\n",
    "X_prepped.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Steps*\n",
    "1. Encode the categorical variables\n",
    "    - OneHotEncoder for non-tree models\n",
    "    - OrdinalEncoder for tree-based models\n",
    "2. Impute missing values on numeric fields\n",
    "    - SimpleImputer [mean, median, most_frequent]\n",
    "3. Scale numerical values\n",
    "4. [optional] normalize features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Notes*\n",
    "- For tree-based models, do not one-hot encode, instead use ordinal encoding. Tree-based models can basically learn the same information from an ordinal encoded feature as from a one-hot encoded feature, even if the features themselves are unordered.\n",
    "- Cross-Validation on the entire pipeline\n",
    "    - Data is split and then applies the pipeline steps (good) instead of preprocessing the data and then do cross-validation on just the model (bad - Data Leakage)\n",
    "    - Preprocessing before splitting the data does not properly simulate reality\n",
    "    - Splitting and then preprocessing does simulate reality, which is the entire purpose of cross-validation\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Preprocessors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of numerical and categorical columns in X data\n",
    "numeric_cols = X_prepped.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_prepped.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a preprocessor for tree-based models\n",
    "treebased_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Development and Testing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models to Test*\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- SVC\n",
    "- Decision Tree\n",
    "- Bagging Decision Tree\n",
    "- Boosted Decision Tree\n",
    "- Random Forest Classifier\n",
    "- Voting Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 1: Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.48026037 1.54868555 1.3789115  1.31208324 1.30005002]\n",
      "score_time [0.11382413 0.09935117 0.0985651  0.09071136 0.10803843]\n",
      "test_score [0.65700209 0.66681046 0.65784216 0.65638907 0.67066276]\n",
      "train_score [0.97544487 0.97531999 0.97638144 0.97743153 0.97623399]\n",
      "-----\n",
      "Average cross-validation test score: 0.6617413071599373\n",
      "Average cross-validation train score: 0.9761623655637937\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperparameter Tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7662735234311978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__min_samples_split': 4, 'model__max_depth': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base ML Pipeline using Decision Tree\n",
    "clf = DecisionTreeClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create the parameter grid for hyper-parameter tuning\n",
    "param_grid = {\n",
    "    'model__max_depth': [2, 4, 6, 8, 10],\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# Test 10 random hyperparameter combinations with 5-fold CV\n",
    "search = RandomizedSearchCV(pipeline, param_grid, n_iter=10, cv=5, scoring='accuracy', return_train_score=False, random_state=42, n_jobs=-1)\n",
    "search.fit(X_prepped, y)\n",
    "\n",
    "# Evaluate results of the search\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "print(f'Best Accuracy: {search.best_score_}')\n",
    "search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Evaluate the Tuned Decision Tree Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [0.7591114  0.70767999 0.69888258 0.70888734 0.70018792]\n",
      "score_time [0.07191324 0.08268356 0.08208036 0.07317662 0.08228111]\n",
      "test_score [0.76630188 0.77926619 0.77558805 0.7549496  0.75512567]\n",
      "train_score [0.76686249 0.76434227 0.76514829 0.77027388 0.77032626]\n",
      "-----\n",
      "Average cross-validation test score: 0.7662462770214905\n",
      "Average cross-validation train score: 0.7673906396182607\n"
     ]
    }
   ],
   "source": [
    "# Initilize Classifier with the best parameters\n",
    "clf = DecisionTreeClassifier(\n",
    "    min_samples_split=2,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "# Create a ML Pipeline Instance with the Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 2: SGDClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Evaluate Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.06982088 1.0507679  1.02597451 1.03102064 1.0332787 ]\n",
      "score_time [0.10078168 0.10587502 0.10735512 0.09990263 0.10965347]\n",
      "test_score [0.76632458 0.76444011 0.76875397 0.75635728 0.76100629]\n",
      "train_score [0.76243508 0.76275294 0.76167447 0.76612459 0.76496231]\n",
      "-----\n",
      "Average cross-validation test score: 0.7633764463095509\n",
      "Average cross-validation train score: 0.7635898794240836\n"
     ]
    }
   ],
   "source": [
    "# Initialize Base Classifier\n",
    "clf = SGDClassifier()\n",
    "\n",
    "# Initialize ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Evaluate Hyperparameter-tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7584540882000183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__penalty': 'l1',\n",
       " 'model__max_iter': 1000,\n",
       " 'model__loss': 'modified_huber',\n",
       " 'model__alpha': 0.0001}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base ML Pipeline using SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create the parameter grid for hyper-parameter tuning\n",
    "param_grid = {\n",
    "    'model__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'model__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'model__max_iter': [1000, 5000, 10000]}\n",
    "\n",
    "# Test 10 random hyperparameter combinations with 5-fold CV\n",
    "search = RandomizedSearchCV(pipeline, param_grid, n_iter=10, cv=5, scoring='accuracy', return_train_score=False, random_state=42, n_jobs=-1)\n",
    "search.fit(X_prepped, y)\n",
    "\n",
    "# Evaluate results of the search\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "print(f'Best Accuracy: {search.best_score_}')\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.30916095 1.39068055 1.20214367 1.1642735  1.30064988]\n",
      "score_time [0.09161973 0.09718871 0.09606147 0.09177518 0.09867525]\n",
      "test_score [0.77027518 0.76419036 0.74477795 0.75692489 0.75823627]\n",
      "train_score [0.7645977  0.7668852  0.76970058 0.77236838 0.77172827]\n",
      "-----\n",
      "Average cross-validation test score: 0.7588809292356239\n",
      "Average cross-validation train score: 0.769056027554112\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tuned Classifier\n",
    "clf = SGDClassifier(\n",
    "    penalty='l1',\n",
    "    max_iter=1000,\n",
    "    loss='modified_huber',\n",
    "    alpha=0.0001\n",
    ")\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [3.36990643 2.58722329 2.31067395 2.3189652  2.31309247]\n",
      "score_time [0.15515924 0.11544895 0.11325622 0.11164474 0.11375284]\n",
      "test_score [0.759  0.7584 0.7496 0.7706 0.7528]\n",
      "train_score [0.98315 0.9837  0.98365 0.9839  0.9836 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.75808\n",
      "Average cross-validation train score: 0.9836\n"
     ]
    }
   ],
   "source": [
    "model = model=RandomForestClassifier()\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', model)])\n",
    "\n",
    "model_evaluation(random_forest_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 500,\n",
       " 'model__min_samples_split': 12,\n",
       " 'model__min_samples_leaf': 2,\n",
       " 'model__max_features': 'log2',\n",
       " 'model__max_depth': 10,\n",
       " 'model__bootstrap': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model=RandomForestClassifier()\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', model)])\n",
    "\n",
    "random_forest_param_grid = {\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__max_depth': [5, 7, 10, 12, 15],\n",
    "    'model__max_features': [None, 'sqrt', 'log2'],\n",
    "    'model__min_samples_leaf': [1, 2, 3],\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10, 12],\n",
    "    'model__n_estimators': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=random_forest_pipeline,\n",
    "    param_distributions=random_forest_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1).fit(X.head(25000), y.head(25000))\n",
    "\n",
    "print(rf_random.best_score_)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [6.54380774 6.54193783 6.28002405 6.67028141 6.45264959]\n",
      "score_time [0.29910493 0.2912569  0.28822875 0.30168414 0.29417658]\n",
      "test_score [0.7644 0.7798 0.768  0.7846 0.7632]\n",
      "train_score [0.7903  0.7912  0.79395 0.7886  0.7916 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.772\n",
      "Average cross-validation train score: 0.7911300000000001\n"
     ]
    }
   ],
   "source": [
    "tuned_model = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=6,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "tuned_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', tuned_model)])\n",
    "\n",
    "# Model Evaluation\n",
    "model_evaluation(tuned_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.93047071, 4.80815029, 4.45945811, 6.02714062, 4.06109238]),\n",
       " 'score_time': array([0.61489248, 0.6098814 , 0.76160836, 0.58727765, 0.58591032]),\n",
       " 'test_score': array([0.7795, 0.771 , 0.784 , 0.7735, 0.784 ])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "cross_validate(estimator=pipeline, X=X_prepped.head(10000), y=y.head(10000), cv=5, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7776000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__kernel': 'rbf', 'model__gamma': 'scale', 'model__C': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_clf = SVC()\n",
    "\n",
    "svc_pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', base_clf)])\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'model__gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=svc_pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1).fit(X.head(25000), y.head(25000))\n",
    "\n",
    "print(search.best_score_)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [27.53406644 26.26263356 26.94116974 26.22585106 27.41593909]\n",
      "score_time [0.49966478 0.49866152 0.4976685  0.48872352 0.48968434]\n",
      "test_score [0.7752 0.7836 0.772  0.7906 0.767 ]\n",
      "train_score [0.7794  0.7795  0.787   0.77925 0.7858 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.7776799999999999\n",
      "Average cross-validation train score: 0.7821899999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "tree = DecisionTreeClassifier(\n",
    "    min_samples_split=8,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "# Initialize a bagging classifier with 10 decision trees\n",
    "bagging = BaggingClassifier(tree, n_estimators=500)\n",
    "\n",
    "bagging_pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', bagging)])\n",
    "\n",
    "model_evaluation(bagging_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model and Predict Test Set        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(fitted_pipeline, submission_name):\n",
    "    # Read kaggle test data from disk\n",
    "    X_test = pd.read_csv('data/test.csv')\n",
    "    \n",
    "    # Prep test data\n",
    "    X_test_prepped = X_test.drop(columns='id')\n",
    "    X_test_prepped = DataPrep().run(X_test_prepped)\n",
    "\n",
    "    # Use fitted model pipeline to predict values on test data\n",
    "    submission = pd.DataFrame({\n",
    "        'id': list(X_test['id']),\n",
    "        'return': fitted_pipeline.predict(X_test_prepped)\n",
    "    })\n",
    "\n",
    "    # Write results to csv file\n",
    "    submission.to_csv(f'./submissions/{submission_name}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['color', 'salutation', 'state', 'order_month',\n",
       "       'customer_return_behavior', 'item_return_behavior',\n",
       "       'manufacturer_return_behavior'],\n",
       "      dtype='object')),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index(['size', 'price', 'customer_age_at_order', 'account_age_months',\n",
       "       'is_delivered'],\n",
       "      dtype='object'))])),\n",
       "                ('model', SVC(C=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = X_prepped.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_prepped.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Initialize Tuned Classifier\n",
    "clf = SVC(\n",
    "    kernel='rbf',\n",
    "    gamma= 'scale',\n",
    "    C= 1)\n",
    "\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "pipeline.fit(X_prepped.head(25000), y.head(25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(pipeline, 'submission3_svc_sampled.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_prepped, y, test_size=.25, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    min_samples_split=2,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', tuned_clf)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658924205378973"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_val, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
