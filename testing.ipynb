{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "1. Create the most accurate classifier (evaluation metric: accuracy rate) for the data, as measured by the\n",
    "test data.\n",
    "2. Write a 8-12 page slides summarizing your approach to:  \n",
    "    (a) cleaning and preparing the data for modeling - Assumption: Missing dates implying no delivery  \n",
    "    (b) formulating the model design matrix - Definition of features  \n",
    "    (c) building the model and tuning parameters - Different models tested and describe the tuning process  \n",
    "    (d) validating the model by training & validation sets, or other approaches - 5-fold Cross-Validation   \n",
    "    (e) comparing results from all attempts  \n",
    "    (f) findings from the data and challenges from this contest.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, LabelEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "from src.datasets import get_training\n",
    "from src.prep import DataPrep\n",
    "from src.utils import model_evaluation_cv, make_predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get and Prepare Training Data**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read training X and y frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_training()\n",
    "X_prepped = DataPrep().run(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Filter training data, removing customers with age > 100*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevent Indexes to keep\n",
    "keep_idx = X_prepped[(X_prepped['customer_age_at_order'] < 100) | (X_prepped['customer_age_at_order'].isna())].index\n",
    "\n",
    "# Filter our data in X and y\n",
    "X_prepped = X_prepped.loc[keep_idx]\n",
    "y = X_prepped.join(y)['return']\n",
    "\n",
    "# Reset index from 0-n\n",
    "X_prepped.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Steps*\n",
    "1. Encode the categorical variables\n",
    "    - OneHotEncoder for non-tree models\n",
    "    - OrdinalEncoder for tree-based models\n",
    "2. Impute missing values on numeric fields\n",
    "    - SimpleImputer [mean, median, most_frequent]\n",
    "3. Scale numerical values\n",
    "4. [optional] normalize features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing Notes*\n",
    "- For tree-based models, do not one-hot encode, instead use ordinal encoding. Tree-based models can basically learn the same information from an ordinal encoded feature as from a one-hot encoded feature, even if the features themselves are unordered.\n",
    "- Cross-Validation on the entire pipeline\n",
    "    - Data is split and then applies the pipeline steps (good) instead of preprocessing the data and then do cross-validation on just the model (bad - Data Leakage)\n",
    "    - Preprocessing before splitting the data does not properly simulate reality\n",
    "    - Splitting and then preprocessing does simulate reality, which is the entire purpose of cross-validation\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Preprocessors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of numerical and categorical columns in X data\n",
    "numeric_cols = X_prepped.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_prepped.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a preprocessor for tree-based models\n",
    "treebased_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Development and Testing**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models to Test*\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- SVC\n",
    "- Decision Tree\n",
    "- Bagging Decision Tree\n",
    "- Boosted Decision Tree\n",
    "- Random Forest Classifier\n",
    "- Voting Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 1: Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.48026037 1.54868555 1.3789115  1.31208324 1.30005002]\n",
      "score_time [0.11382413 0.09935117 0.0985651  0.09071136 0.10803843]\n",
      "test_score [0.65700209 0.66681046 0.65784216 0.65638907 0.67066276]\n",
      "train_score [0.97544487 0.97531999 0.97638144 0.97743153 0.97623399]\n",
      "-----\n",
      "Average cross-validation test score: 0.6617413071599373\n",
      "Average cross-validation train score: 0.9761623655637937\n"
     ]
    }
   ],
   "source": [
    "# Initialize Base Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize a Base ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate performance on base model\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperparameter Tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Accuracy: 0.7669682858975142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__splitter': 'random',\n",
       " 'model__min_samples_split': 4,\n",
       " 'model__max_depth': 8,\n",
       " 'model__criterion': 'gini'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base ML Pipeline using Decision Tree\n",
    "clf = DecisionTreeClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create the parameter grid for hyper-parameter tuning\n",
    "param_grid = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [2, 4, 6, 8, 10],\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'model__splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# Test 10 random hyperparameter combinations with 5-fold CV\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline, param_grid, n_iter=20, cv=5, scoring='accuracy',\n",
    "    verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "search.fit(X_prepped, y)\n",
    "\n",
    "# Evaluate results of the search\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "print(f'Best Accuracy: {search.best_score_}')\n",
    "search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Evaluate the Tuned Decision Tree Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [0.59907317 0.61742568 0.58986616 0.58256817 0.56883979]\n",
      "score_time [0.06925344 0.10107183 0.08158183 0.08467603 0.08393431]\n",
      "test_score [0.76139769 0.77940242 0.76507583 0.75685678 0.75689667]\n",
      "train_score [0.769553   0.76614162 0.7709834  0.77363417 0.77343111]\n",
      "-----\n",
      "Average cross-validation test score: 0.7639258781975714\n",
      "Average cross-validation train score: 0.7707486607848851\n"
     ]
    }
   ],
   "source": [
    "# Initilize Classifier with the best parameters\n",
    "clf = DecisionTreeClassifier(\n",
    "    min_samples_split=4,\n",
    "    max_depth=8,\n",
    "    splitter='random',\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "# Create a ML Pipeline Instance with the Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 2: SGDClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Evaluate Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.06982088 1.0507679  1.02597451 1.03102064 1.0332787 ]\n",
      "score_time [0.10078168 0.10587502 0.10735512 0.09990263 0.10965347]\n",
      "test_score [0.76632458 0.76444011 0.76875397 0.75635728 0.76100629]\n",
      "train_score [0.76243508 0.76275294 0.76167447 0.76612459 0.76496231]\n",
      "-----\n",
      "Average cross-validation test score: 0.7633764463095509\n",
      "Average cross-validation train score: 0.7635898794240836\n"
     ]
    }
   ],
   "source": [
    "# Initialize Base Classifier\n",
    "clf = SGDClassifier()\n",
    "\n",
    "# Initialize ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Evaluate Hyperparameter-tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7584540882000183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__penalty': 'l1',\n",
       " 'model__max_iter': 1000,\n",
       " 'model__loss': 'modified_huber',\n",
       " 'model__alpha': 0.0001}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create base ML Pipeline using SGDClassifier\n",
    "clf = SGDClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create the parameter grid for hyper-parameter tuning\n",
    "param_grid = {\n",
    "    'model__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'model__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'model__max_iter': [1000, 5000, 10000]}\n",
    "\n",
    "# Test 10 random hyperparameter combinations with 5-fold CV\n",
    "search = RandomizedSearchCV(pipeline, param_grid, n_iter=10, cv=5, scoring='accuracy', return_train_score=False, random_state=42, n_jobs=-1)\n",
    "search.fit(X_prepped, y)\n",
    "\n",
    "# Evaluate results of the search\n",
    "search_df = pd.DataFrame(search.cv_results_)\n",
    "print(f'Best Accuracy: {search.best_score_}')\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [1.30916095 1.39068055 1.20214367 1.1642735  1.30064988]\n",
      "score_time [0.09161973 0.09718871 0.09606147 0.09177518 0.09867525]\n",
      "test_score [0.77027518 0.76419036 0.74477795 0.75692489 0.75823627]\n",
      "train_score [0.7645977  0.7668852  0.76970058 0.77236838 0.77172827]\n",
      "-----\n",
      "Average cross-validation test score: 0.7588809292356239\n",
      "Average cross-validation train score: 0.769056027554112\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tuned Classifier\n",
    "clf = SGDClassifier(\n",
    "    penalty='l1',\n",
    "    max_iter=1000,\n",
    "    loss='modified_huber',\n",
    "    alpha=0.0001\n",
    ")\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "model_evaluation_cv(pipeline, X_prepped, y, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [3.36990643 2.58722329 2.31067395 2.3189652  2.31309247]\n",
      "score_time [0.15515924 0.11544895 0.11325622 0.11164474 0.11375284]\n",
      "test_score [0.759  0.7584 0.7496 0.7706 0.7528]\n",
      "train_score [0.98315 0.9837  0.98365 0.9839  0.9836 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.75808\n",
      "Average cross-validation train score: 0.9836\n"
     ]
    }
   ],
   "source": [
    "model = model=RandomForestClassifier()\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', model)])\n",
    "\n",
    "model_evaluation(random_forest_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 500,\n",
       " 'model__min_samples_split': 12,\n",
       " 'model__min_samples_leaf': 2,\n",
       " 'model__max_features': 'log2',\n",
       " 'model__max_depth': 10,\n",
       " 'model__bootstrap': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model=RandomForestClassifier()\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', model)])\n",
    "\n",
    "random_forest_param_grid = {\n",
    "    'model__bootstrap': [True, False],\n",
    "    'model__max_depth': [5, 7, 10, 12, 15],\n",
    "    'model__max_features': [None, 'sqrt', 'log2'],\n",
    "    'model__min_samples_leaf': [1, 2, 3],\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10, 12],\n",
    "    'model__n_estimators': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=random_forest_pipeline,\n",
    "    param_distributions=random_forest_param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1).fit(X.head(25000), y.head(25000))\n",
    "\n",
    "print(rf_random.best_score_)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [6.54380774 6.54193783 6.28002405 6.67028141 6.45264959]\n",
      "score_time [0.29910493 0.2912569  0.28822875 0.30168414 0.29417658]\n",
      "test_score [0.7644 0.7798 0.768  0.7846 0.7632]\n",
      "train_score [0.7903  0.7912  0.79395 0.7886  0.7916 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.772\n",
      "Average cross-validation train score: 0.7911300000000001\n"
     ]
    }
   ],
   "source": [
    "tuned_model = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=6,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "tuned_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', tuned_model)])\n",
    "\n",
    "# Model Evaluation\n",
    "model_evaluation(tuned_pipeline, X.head(25000), y.head(25000), cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = X_prepped.sample(25000).join(y)\n",
    "X_prepped_sample = sampled_df.drop(columns=['return'])\n",
    "y_sample = sampled_df['return']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Evaluate Performance on Base Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([23.12288785, 25.16459703, 22.36177158, 22.81326747, 21.2776823 ]),\n",
       " 'score_time': array([3.48576641, 2.9429872 , 2.89863014, 2.67603254, 2.62749577]),\n",
       " 'test_score': array([0.7772, 0.7844, 0.7684, 0.7874, 0.7604])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Base SVC Model\n",
    "clf = SVC()\n",
    "\n",
    "# Initialize base ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Base Model Performance\n",
    "cross_validate(estimator=pipeline, X=X_prepped.head(25000), y=y.head(25000), cv=5, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Evaluate hyperparameter tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__kernel': 'rbf', 'model__gamma': 'scale', 'model__C': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a base pipelipe\n",
    "clf = SVC()\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Create Parameter Grid for RandomizedSearch\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'model__gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Runing Hyperparameter Tuning Search Procedure\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1).fit(X_prepped_sample, y_sample)\n",
    "\n",
    "# Evaluate best model parameters\n",
    "print(search.best_score_)\n",
    "search.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3: Evaluate performace of tuned model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tuned SVC Model\n",
    "clf = SVC(\n",
    "    kernel='rbf',\n",
    "    gammer='scale',\n",
    "    C=1\n",
    ")\n",
    "\n",
    "# Initialize Tuned ML Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "# Evaluate Tuned Model Performance\n",
    "cross_validate(estimator=pipeline, X=X_prepped_sample, y=y_sample, cv=5, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = X_prepped.sample(25000).join(y)\n",
    "X_prepped_sample = sampled_df.drop(columns=['return'])\n",
    "y_sample = sampled_df['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [10.23965383 10.5209434  10.18956566 10.10906339 10.14805746]\n",
      "score_time [0.32194686 0.36301517 0.29652238 0.29341698 0.31455374]\n",
      "test_score [0.772  0.7706 0.7562 0.7728 0.773 ]\n",
      "train_score [0.76915 0.7692  0.77275 0.7692  0.7693 ]\n",
      "-----\n",
      "Average cross-validation test score: 0.76892\n",
      "Average cross-validation train score: 0.7699199999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize a decision tree classifier\n",
    "tree = DecisionTreeClassifier(\n",
    "    min_samples_split=8,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "# Initialize a bagging classifier with 10 decision trees\n",
    "bagging = BaggingClassifier(tree, n_estimators=500)\n",
    "\n",
    "bagging_pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', bagging)])\n",
    "\n",
    "model_evaluation_cv(bagging_pipeline, X_prepped_sample, y_sample, cv=5, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model and Predict Test Set        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['color', 'salutation', 'state', 'order_month',\n",
       "       'customer_return_behavior', 'item_return_behavior',\n",
       "       'manufacturer_return_behavior'],\n",
       "      dtype='object')),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index(['size', 'price', 'customer_age_at_order', 'account_age_months',\n",
       "       'is_delivered'],\n",
       "      dtype='object'))])),\n",
       "                ('model', SVC(C=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = X_prepped.select_dtypes(include=np.number).columns\n",
    "categorical_cols = X_prepped.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Create a generic preprocessor\n",
    "generic_preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]),categorical_cols),\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        ]), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Initialize Tuned Classifier\n",
    "clf = SVC(\n",
    "    kernel='rbf',\n",
    "    gamma= 'scale',\n",
    "    C= 1)\n",
    "\n",
    "\n",
    "# Initialize ML Pipeline with Tuned Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', generic_preprocessor),\n",
    "    ('model', clf)])\n",
    "\n",
    "pipeline.fit(X_prepped.head(25000), y.head(25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions(pipeline, 'submission3_svc_sampled.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_prepped, y, test_size=.25, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    min_samples_split=2,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', treebased_preprocessor),\n",
    "    ('model', tuned_clf)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658924205378973"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_val, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
